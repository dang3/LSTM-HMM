{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554448\n",
      "Thank you very much, everybody.  Thank you.   So we're just going to let the other folks come in, fill it up.  This is some crowd.  You have to see what's outside, you wouldn't even believe it.  Unbelievable.\r\n",
      "\r\n",
      "So I'm thrilled to be here in Nashvill\n"
     ]
    }
   ],
   "source": [
    "file_path = \"dataset/donaldTrump.txt\"\n",
    "text = open(file_path, 'rb').read().decode(encoding='utf-8')\n",
    "print(len(text))\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "# Get all set of all unique chars\n",
    "uniqueChars = sorted(set(text))\n",
    "\n",
    "print(len(uniqueChars))\n",
    "\n",
    "char2int = dict()\n",
    "int2char = dict()\n",
    "\n",
    "for i, ch in enumerate(uniqueChars):\n",
    "    char2int[ch] = i\n",
    "    int2char[i] = ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training examples\n",
    "\n",
    "Break chars into sequences of length 40. Feed 40 chars into the NN and let the NN generate the next char. The next char is the 41st character. Train the NN to output this 41st char. Then move over by 3 letters to make next sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ry much, everybody.  Thank you.   So we'\n",
      "r\n"
     ]
    }
   ],
   "source": [
    "seq_len = 40\n",
    "step = 3\n",
    "\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    sequences.append(text[i : i + seq_len])\n",
    "    next_chars.append(text[i + seq_len])\n",
    "\n",
    "print(sequences[4])\n",
    "print(next_chars[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
